{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LkkSQr6o_i7A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, precision_recall_curve,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "hDDOn3bFJ5ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/cleaned_fraud_df.csv\")\n",
        "use_cols = ['age_group','gender_clean','category_clean','amount_bin','merchant','customer','fraud']\n",
        "df = df[use_cols].copy()\n",
        "\n",
        "y = df['fraud'].astype(int).values\n",
        "X = df.drop(columns=['fraud'])\n",
        "\n",
        "# Stratified 70/15/15 split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
        ")\n",
        "print(\"Train:\", X_train.shape, y_train.mean())\n",
        "print(\"Valid:\", X_valid.shape, y_valid.mean())\n",
        "print(\"Test :\", X_test.shape,  y_test.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKE8oMN3SkWD",
        "outputId": "c961fa44-a7da-4e2e-d130-31b49abf5511"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (416250, 6) 0.012108108108108109\n",
            "Valid: (89196, 6) 0.012108166285483654\n",
            "Test : (89197, 6) 0.012108030539143694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoders\n",
        "# TargetEncoder for IDs (identity signal, leakage-safe, smoothed)\n",
        "# CountEncoder for IDs (popularity signal, log-scaled)\n",
        "# OneHot for low-card categoricals\n",
        "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Smoothed target encoding: for each category v,\n",
        "        enc(v) = (sum_y + prior * m) / (count + m)\n",
        "    where prior = global mean, m = smoothing.\n",
        "    Unseen categories map to prior. Safe inside CV/Pipeline.\n",
        "    \"\"\"\n",
        "    def __init__(self, cols, smoothing=200):\n",
        "        self.cols = cols\n",
        "        self.smoothing = smoothing\n",
        "        self.maps_ = {}\n",
        "        self.prior_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = X.copy()\n",
        "        y = pd.Series(y)\n",
        "        self.prior_ = float(y.mean())\n",
        "        self.maps_ = {}\n",
        "        for c in self.cols:\n",
        "            s = X[c].astype(str)\n",
        "            stats = y.groupby(s).agg(['sum','count'])\n",
        "            enc = (stats['sum'] + self.prior_ * self.smoothing) / (stats['count'] + self.smoothing)\n",
        "            self.maps_[c] = enc\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        feats = []\n",
        "        for c in self.cols:\n",
        "            m = self.maps_.get(c, pd.Series(dtype=float))\n",
        "            v = X[c].astype(str).map(m).fillna(self.prior_)\n",
        "            feats.append(v.astype('float32').to_numpy().reshape(-1, 1))\n",
        "        return np.hstack(feats)\n",
        "\n",
        "class CountEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Unsupervised frequency (count) encoding with optional log scaling.\n",
        "    \"\"\"\n",
        "    def __init__(self, cols, normalize=False, log1p=True):\n",
        "        self.cols = cols\n",
        "        self.normalize = normalize\n",
        "        self.log1p = log1p\n",
        "        self.maps_ = {}\n",
        "        self.n_train_ = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = X.copy()\n",
        "        self.n_train_ = len(X)\n",
        "        self.maps_ = {}\n",
        "        for c in self.cols:\n",
        "            vc = X[c].astype(str).value_counts()\n",
        "            if self.normalize:\n",
        "                vc = vc / self.n_train_\n",
        "            self.maps_[c] = vc\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        feats = []\n",
        "        for c in self.cols:\n",
        "            m = self.maps_.get(c, pd.Series(dtype=float))\n",
        "            enc = X[c].astype(str).map(m).fillna(0.0)\n",
        "            if self.log1p and not self.normalize:\n",
        "                enc = np.log1p(enc)  # log(count)\n",
        "            elif self.log1p and self.normalize:\n",
        "                enc = np.log1p(enc * self.n_train_)  # ~log(count)\n",
        "            feats.append(enc.astype('float32').to_numpy().reshape(-1, 1))\n",
        "        return np.hstack(feats)\n",
        "\n",
        "low_card  = ['age_group','gender_clean','category_clean','amount_bin']\n",
        "high_card = ['merchant','customer']\n",
        "\n",
        "# Small feature space: dense is fine\n",
        "try:\n",
        "    # scikit-learn >= 1.2\n",
        "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "except TypeError:\n",
        "    # scikit-learn < 1.2\n",
        "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('ohe',  ohe, low_card),\n",
        "        ('te',   TargetEncoder(high_card, smoothing=200), high_card),\n",
        "        ('freq', CountEncoder(high_card, normalize=False, log1p=True), high_card),\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")"
      ],
      "metadata": {
        "id": "ylsXOiYgSn9S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=600,\n",
        "    max_depth=12,\n",
        "    min_samples_leaf=100,          # prevent tiny pure leaves (helps against tail overfit)\n",
        "    max_features='sqrt',\n",
        "    class_weight='balanced_subsample',  # imbalance-aware per tree\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    oob_score=True\n",
        ")\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('pre', preprocess),\n",
        "    ('rf',  rf)\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "print(\"OOB score:\", getattr(pipe.named_steps['rf'], 'oob_score_', None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va6mtelqSrWx",
        "outputId": "d3f8d47f-7db6-423d-f924-d1a9164d1c89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB score: 0.9599783783783784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_at_threshold(model, X, y, thr):\n",
        "    proba = model.predict_proba(X)[:, 1]\n",
        "    pred  = (proba >= thr).astype(int)\n",
        "    ap  = average_precision_score(y, proba)\n",
        "    auc = roc_auc_score(y, proba)\n",
        "    print(f\"AUC-PR: {ap:.4f} | ROC-AUC: {auc:.4f} | thr={thr:.4f} | prevalence={y.mean():.4f}\")\n",
        "    print(classification_report(y, pred, digits=3))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y, pred))\n",
        "    return ap, auc\n",
        "\n",
        "proba_valid = pipe.predict_proba(X_valid)[:, 1]\n",
        "prec, rec, thr = precision_recall_curve(y_valid, proba_valid)\n",
        "f1  = 2*prec*rec/(prec+rec+1e-9)\n",
        "best_idx = int(np.nanargmax(f1[:-1]))  # thresholds has length len(prec)-1\n",
        "thr_star = float(thr[best_idx])\n",
        "print(\"Chosen threshold (max F1 on VALID):\", thr_star)\n",
        "\n",
        "_ = evaluate_at_threshold(pipe, X_valid, y_valid, thr_star)\n",
        "_ = evaluate_at_threshold(pipe, X_test,  y_test,  thr_star)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opXtVZ58Svpf",
        "outputId": "93474a34-d360-48d5-ad09-6d10487b4d23"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen threshold (max F1 on VALID): 0.9431542501590449\n",
            "AUC-PR: 0.8226 | ROC-AUC: 0.9963 | thr=0.9432 | prevalence=0.0121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.997     0.997     0.997     88116\n",
            "           1      0.772     0.725     0.748      1080\n",
            "\n",
            "    accuracy                          0.994     89196\n",
            "   macro avg      0.884     0.861     0.872     89196\n",
            "weighted avg      0.994     0.994     0.994     89196\n",
            "\n",
            "Confusion matrix:\n",
            " [[87885   231]\n",
            " [  297   783]]\n",
            "AUC-PR: 0.8297 | ROC-AUC: 0.9967 | thr=0.9432 | prevalence=0.0121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.997     0.997     0.997     88117\n",
            "           1      0.779     0.736     0.757      1080\n",
            "\n",
            "    accuracy                          0.994     89197\n",
            "   macro avg      0.888     0.867     0.877     89197\n",
            "weighted avg      0.994     0.994     0.994     89197\n",
            "\n",
            "Confusion matrix:\n",
            " [[87892   225]\n",
            " [  285   795]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "def metrics_by_bin(model, X, y, bin_series, thr):\n",
        "    proba = model.predict_proba(X)[:,1]\n",
        "    pred  = (proba >= thr).astype(int)\n",
        "    dfm = pd.DataFrame({'bin': bin_series.values, 'y': y, 'proba': proba, 'pred': pred})\n",
        "    rows = []\n",
        "    for b, g in dfm.groupby('bin'):\n",
        "        if len(g) == 0:\n",
        "            continue\n",
        "        ap  = average_precision_score(g['y'], g['proba']) if g['y'].sum()>0 else np.nan\n",
        "        auc = roc_auc_score(g['y'], g['proba']) if g['y'].nunique()>1 else np.nan\n",
        "        tp = ((g['pred']==1)&(g['y']==1)).sum()\n",
        "        fp = ((g['pred']==1)&(g['y']==0)).sum()\n",
        "        fn = ((g['pred']==0)&(g['y']==1)).sum()\n",
        "        prec = tp/(tp+fp+1e-9); rec = tp/(tp+fn+1e-9)\n",
        "        rows.append([b, len(g), int(g['y'].sum()), ap, auc, prec, rec])\n",
        "    return pd.DataFrame(rows, columns=['amount_bin','n','frauds','AP','ROC_AUC','Precision','Recall']).sort_values('n', ascending=False)\n",
        "\n",
        "print(\"\\nPer-bin metrics (VALID):\")\n",
        "print(metrics_by_bin(pipe, X_valid, y_valid, X_valid['amount_bin'], thr_star))\n",
        "\n",
        "print(\"\\nPer-bin metrics (TEST):\")\n",
        "print(metrics_by_bin(pipe, X_test, y_test, X_test['amount_bin'], thr_star))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWjUFzHJS74R",
        "outputId": "260ac8cd-fcc5-4092-d91f-2688a6445d2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Per-bin metrics (VALID):\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32622      48  0.298446  0.994553   0.600000  0.062500\n",
            "2      10–25  25376      32  0.228034  0.993614   0.000000  0.000000\n",
            "0       0–10  16059      17  0.273962  0.993442   0.000000  0.000000\n",
            "8      50–75  10186      51  0.448161  0.990454   0.541667  0.254902\n",
            "9     75–150   3183     115  0.348547  0.929236   0.403509  0.400000\n",
            "3    150–250    953     164  0.589594  0.893706   0.522843  0.628049\n",
            "5    250–500    500     343  0.936744  0.890773   0.868074  0.959184\n",
            "7   500–1000    219     214  0.983757  0.559813   0.980392  0.934579\n",
            "1  1000–2500     49      47  0.959537  0.361702   0.953488  0.872340\n",
            "4      2500+     49      49  1.000000       NaN   1.000000  0.959184\n",
            "\n",
            "Per-bin metrics (TEST):\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32667      45  0.273644  0.995216   1.000000  0.022222\n",
            "2      10–25  25133      26  0.284144  0.997001   0.000000  0.000000\n",
            "0       0–10  16083      21  0.339113  0.995589   0.000000  0.000000\n",
            "8      50–75  10214      37  0.380996  0.987701   0.777778  0.189189\n",
            "9     75–150   3315     129  0.452839  0.934891   0.520408  0.395349\n",
            "3    150–250    946     163  0.601669  0.885786   0.482906  0.693252\n",
            "5    250–500    503     337  0.942981  0.906180   0.880435  0.961424\n",
            "7   500–1000    235     229  0.981626  0.498544   0.972727  0.934498\n",
            "4      2500+     51      51  1.000000       NaN   1.000000  0.960784\n",
            "1  1000–2500     50      42  0.917802  0.696429   0.878049  0.857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_dist = {\n",
        "    'rf__n_estimators':    [400, 600, 800],\n",
        "    'rf__max_depth':       [8, 10, 12, 16, None],\n",
        "    'rf__min_samples_leaf':[50, 100, 150, 200, 300],\n",
        "    'rf__max_features':    ['sqrt', 0.2, 0.3, 0.4],\n",
        "    'rf__class_weight':    ['balanced', 'balanced_subsample']\n",
        "}\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    pipe,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    scoring='average_precision',   # PR-AUC suits imbalance\n",
        "    n_jobs=-1,\n",
        "    cv=cv,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Best PR-AUC (CV):\", search.best_score_)\n",
        "print(\"Best params:\", search.best_params_)\n",
        "\n",
        "best_model = search.best_estimator_\n",
        "\n",
        "# Re-pick threshold on VALID using best model\n",
        "proba_valid = best_model.predict_proba(X_valid)[:,1]\n",
        "prec, rec, thr = precision_recall_curve(y_valid, proba_valid)\n",
        "f1  = 2*prec*rec/(prec+rec+1e-9)\n",
        "best_idx = int(np.nanargmax(f1[:-1]))\n",
        "thr_star = float(thr[best_idx])\n",
        "print(\"Chosen threshold (max F1, VALID):\", thr_star)\n",
        "\n",
        "_ = evaluate_at_threshold(best_model, X_valid, y_valid, thr_star)\n",
        "_ = evaluate_at_threshold(best_model, X_test,  y_test,  thr_star)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khy4KTF9TBZI",
        "outputId": "909bc9af-1b3b-4f74-8c9d-1e01392ad221"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "Best PR-AUC (CV): 0.8640920151996957\n",
            "Best params: {'rf__n_estimators': 800, 'rf__min_samples_leaf': 50, 'rf__max_features': 0.3, 'rf__max_depth': 16, 'rf__class_weight': 'balanced'}\n",
            "Chosen threshold (max F1, VALID): 0.9398871609573412\n",
            "AUC-PR: 0.8660 | ROC-AUC: 0.9972 | thr=0.9399 | prevalence=0.0121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.998     0.997     0.997     88116\n",
            "           1      0.769     0.797     0.783      1080\n",
            "\n",
            "    accuracy                          0.995     89196\n",
            "   macro avg      0.883     0.897     0.890     89196\n",
            "weighted avg      0.995     0.995     0.995     89196\n",
            "\n",
            "Confusion matrix:\n",
            " [[87857   259]\n",
            " [  219   861]]\n",
            "AUC-PR: 0.8706 | ROC-AUC: 0.9975 | thr=0.9399 | prevalence=0.0121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.998     0.997     0.997     88117\n",
            "           1      0.758     0.809     0.783      1080\n",
            "\n",
            "    accuracy                          0.995     89197\n",
            "   macro avg      0.878     0.903     0.890     89197\n",
            "weighted avg      0.995     0.995     0.995     89197\n",
            "\n",
            "Confusion matrix:\n",
            " [[87838   279]\n",
            " [  206   874]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPer-bin metrics (TEST):\")\n",
        "print(metrics_by_bin(best_model, X_test, y_test, X_test['amount_bin'], thr_star))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tg3pBq4-PZz",
        "outputId": "beedc039-62db-4a6e-d34e-6916d81035d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Per-bin metrics (TEST):\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32667      45  0.336023  0.996426   0.424242  0.311111\n",
            "2      10–25  25133      26  0.343598  0.997658   0.400000  0.307692\n",
            "0       0–10  16083      21  0.392997  0.995879   0.571429  0.190476\n",
            "8      50–75  10214      37  0.423899  0.989592   0.583333  0.378378\n",
            "9     75–150   3315     129  0.536474  0.949614   0.500000  0.426357\n",
            "3    150–250    946     163  0.728006  0.929001   0.522727  0.846626\n",
            "5    250–500    503     337  0.965517  0.938517   0.886792  0.976261\n",
            "7   500–1000    235     229  0.989746  0.671033   0.973568  0.965066\n",
            "4      2500+     51      51  1.000000       NaN   1.000000  1.000000\n",
            "1  1000–2500     50      42  0.923997  0.705357   0.869565  0.952381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(best_model if 'best_model' in locals() else pipe, \"/content/drive/MyDrive/fraud_model/rf_pipeline.joblib\")\n",
        "\n",
        "# Save threshold and a short model card\n",
        "with open(\"/content/drive/MyDrive/fraud_model/rf_threshold.txt\",\"w\") as f:\n",
        "    f.write(str(float(thr_star)))\n",
        "\n",
        "print(\"Saved: rf_pipeline.joblib, rf_threshold.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lTXXHMSTEXw",
        "outputId": "fdbad1c0-85c4-4085-d273-c41f991bd177"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: rf_pipeline.joblib, rf_threshold.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the tuned model if you ran RandomizedSearch; otherwise fall back to the baseline\n",
        "model_current = best_model if 'best_model' in globals() else pipe\n"
      ],
      "metadata": {
        "id": "QJu9EEzn_eRl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score\n",
        "\n",
        "def metrics_by_bin_from_preds(y, proba, pred, bin_series):\n",
        "    dfm = pd.DataFrame({'bin': bin_series.values, 'y': y, 'proba': proba, 'pred': pred})\n",
        "    rows = []\n",
        "    for b, g in dfm.groupby('bin'):\n",
        "        if len(g) == 0:\n",
        "            continue\n",
        "        ap  = average_precision_score(g['y'], g['proba']) if g['y'].sum()>0 else np.nan\n",
        "        auc = roc_auc_score(g['y'], g['proba']) if g['y'].nunique()>1 else np.nan\n",
        "        tp = ((g['pred']==1)&(g['y']==1)).sum()\n",
        "        fp = ((g['pred']==1)&(g['y']==0)).sum()\n",
        "        fn = ((g['pred']==0)&(g['y']==1)).sum()\n",
        "        prec = tp/(tp+fp+1e-9); rec = tp/(tp+fn+1e-9)\n",
        "        rows.append([b, len(g), int(g['y'].sum()), ap, auc, prec, rec])\n",
        "    return pd.DataFrame(rows, columns=['amount_bin','n','frauds','AP','ROC_AUC','Precision','Recall']).sort_values('n', ascending=False)\n",
        "\n",
        "def metrics_by_bin(model, X, y, bin_series, thr):\n",
        "    proba = model.predict_proba(X)[:,1]\n",
        "    pred  = (proba >= float(thr)).astype(int)\n",
        "    return metrics_by_bin_from_preds(y, proba, pred, bin_series)\n",
        "\n",
        "def thresholds_per_bin(model, X_valid, y_valid, bin_valid, strategy=\"max_f1\", min_recall=None):\n",
        "    \"\"\"\n",
        "    Learn a threshold per amount_bin from VALID set.\n",
        "    strategy=\"max_f1\" or \"recall_floor\" (then provide min_recall).\n",
        "    \"\"\"\n",
        "    proba = model.predict_proba(X_valid)[:,1]\n",
        "    dfv = pd.DataFrame({'bin': bin_valid.values, 'y': y_valid, 'p': proba})\n",
        "    thr_map = {}\n",
        "    for b, g in dfv.groupby('bin'):\n",
        "        if g['y'].sum() == 0:\n",
        "            thr_map[b] = 0.999  # ultra high: don't trigger for a bin with no positives\n",
        "            continue\n",
        "        prec, rec, thr = precision_recall_curve(g['y'], g['p'])\n",
        "        if strategy == \"max_f1\":\n",
        "            f1 = 2*prec*rec/(prec+rec+1e-9)\n",
        "            idx = int(np.nanargmax(f1[:-1]))\n",
        "        elif strategy == \"recall_floor\":\n",
        "            floor = 0.5 if min_recall is None else float(min_recall)\n",
        "            ok = np.where(rec[:-1] >= floor)[0]\n",
        "            idx = ok[-1] if len(ok) else len(thr)-1\n",
        "        else:\n",
        "            raise ValueError(\"Unknown strategy\")\n",
        "        thr_map[b] = float(thr[idx])\n",
        "    return thr_map\n",
        "\n",
        "def predict_with_bin_thresholds(model, X, bin_series, thr_map, default_thr):\n",
        "    proba = model.predict_proba(X)[:,1]\n",
        "    thrs = bin_series.map(thr_map).fillna(float(default_thr)).astype(float).values\n",
        "    pred = (proba >= thrs).astype(int)\n",
        "    return proba, pred\n"
      ],
      "metadata": {
        "id": "wn4yPl3f_nf4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    thr_star\n",
        "except NameError:\n",
        "    from sklearn.metrics import precision_recall_curve\n",
        "    pv = model_current.predict_proba(X_valid)[:,1]\n",
        "    P, R, T = precision_recall_curve(y_valid, pv)\n",
        "    F1 = 2*P*R/(P+R+1e-9)\n",
        "    thr_star = float(T[int(np.nanargmax(F1[:-1]))])\n",
        "    print(\"Computed thr_star (VALID, max F1):\", thr_star)\n",
        "\n",
        "print(\"\\n=== BEFORE: Global threshold per-bin metrics (VALID) ===\")\n",
        "valid_before = metrics_by_bin(model_current, X_valid, y_valid, X_valid['amount_bin'], thr_star)\n",
        "print(valid_before)\n",
        "\n",
        "print(\"\\n=== BEFORE: Global threshold per-bin metrics (TEST) ===\")\n",
        "test_before  = metrics_by_bin(model_current, X_test,  y_test,  X_test['amount_bin'],  thr_star)\n",
        "print(test_before)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PLVP_IO_p0g",
        "outputId": "ddd4b577-81ac-4574-b6ce-8938284f6519"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== BEFORE: Global threshold per-bin metrics (VALID) ===\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32622      48  0.408349  0.995106   0.472222  0.354167\n",
            "2      10–25  25376      32  0.282457  0.994567   0.583333  0.218750\n",
            "0       0–10  16059      17  0.295404  0.993647   0.428571  0.176471\n",
            "8      50–75  10186      51  0.524545  0.991389   0.638889  0.450980\n",
            "9     75–150   3183     115  0.431653  0.948156   0.415929  0.408696\n",
            "3    150–250    953     164  0.712168  0.931010   0.570833  0.835366\n",
            "5    250–500    500     343  0.968363  0.937568   0.887097  0.962099\n",
            "7   500–1000    219     214  0.992332  0.722430   0.975962  0.948598\n",
            "1  1000–2500     49      47  0.959224  0.351064   0.957447  0.957447\n",
            "4      2500+     49      49  1.000000       NaN   1.000000  1.000000\n",
            "\n",
            "=== BEFORE: Global threshold per-bin metrics (TEST) ===\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32667      45  0.336023  0.996426   0.424242  0.311111\n",
            "2      10–25  25133      26  0.343598  0.997658   0.400000  0.307692\n",
            "0       0–10  16083      21  0.392997  0.995879   0.571429  0.190476\n",
            "8      50–75  10214      37  0.423899  0.989592   0.583333  0.378378\n",
            "9     75–150   3315     129  0.536474  0.949614   0.500000  0.426357\n",
            "3    150–250    946     163  0.728006  0.929001   0.522727  0.846626\n",
            "5    250–500    503     337  0.965517  0.938517   0.886792  0.976261\n",
            "7   500–1000    235     229  0.989746  0.671033   0.973568  0.965066\n",
            "4      2500+     51      51  1.000000       NaN   1.000000  1.000000\n",
            "1  1000–2500     50      42  0.923997  0.705357   0.869565  0.952381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learn a threshold per amount_bin (on VALID) using max-F1 within each bin\n",
        "thr_map = thresholds_per_bin(model_current, X_valid, y_valid, X_valid['amount_bin'], strategy=\"max_f1\")\n",
        "\n",
        "# Evaluate on VALID with per-bin thresholds (for reference)\n",
        "proba_v, pred_v = predict_with_bin_thresholds(model_current, X_valid, X_valid['amount_bin'], thr_map, default_thr=thr_star)\n",
        "valid_after_thr = metrics_by_bin_from_preds(y_valid, proba_v, pred_v, X_valid['amount_bin'])\n",
        "\n",
        "# Evaluate on TEST with those per-bin thresholds\n",
        "proba_t, pred_t = predict_with_bin_thresholds(model_current, X_test,  X_test['amount_bin'],  thr_map, default_thr=thr_star)\n",
        "test_after_thr  = metrics_by_bin_from_preds(y_test,  proba_t, pred_t, X_test['amount_bin'])\n",
        "\n",
        "print(\"\\n=== AFTER (Per-bin thresholds): per-bin metrics (VALID) ===\")\n",
        "print(valid_after_thr)\n",
        "\n",
        "print(\"\\n=== AFTER (Per-bin thresholds): per-bin metrics (TEST) ===\")\n",
        "print(test_after_thr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4fp9Ri__sRY",
        "outputId": "aae5191c-ce8a-4040-f87c-524c64c2a82d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== AFTER (Per-bin thresholds): per-bin metrics (VALID) ===\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32622      48  0.408349  0.995106   0.393443  0.500000\n",
            "2      10–25  25376      32  0.282457  0.994567   0.450000  0.281250\n",
            "0       0–10  16059      17  0.295404  0.993647   0.375000  0.352941\n",
            "8      50–75  10186      51  0.524545  0.991389   0.551724  0.627451\n",
            "9     75–150   3183     115  0.431653  0.948156   0.394904  0.539130\n",
            "3    150–250    953     164  0.712168  0.931010   0.568548  0.859756\n",
            "5    250–500    500     343  0.968363  0.937568   0.900552  0.950437\n",
            "7   500–1000    219     214  0.992332  0.722430   0.977169  1.000000\n",
            "1  1000–2500     49      47  0.959224  0.351064   0.959184  1.000000\n",
            "4      2500+     49      49  1.000000       NaN   1.000000  0.979592\n",
            "\n",
            "=== AFTER (Per-bin thresholds): per-bin metrics (TEST) ===\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32667      45  0.336023  0.996426   0.333333  0.444444\n",
            "2      10–25  25133      26  0.343598  0.997658   0.333333  0.384615\n",
            "0       0–10  16083      21  0.392997  0.995879   0.636364  0.333333\n",
            "8      50–75  10214      37  0.423899  0.989592   0.405405  0.405405\n",
            "9     75–150   3315     129  0.536474  0.949614   0.425287  0.573643\n",
            "3    150–250    946     163  0.728006  0.929001   0.516364  0.871166\n",
            "5    250–500    503     337  0.965517  0.938517   0.902507  0.961424\n",
            "7   500–1000    235     229  0.989746  0.671033   0.974468  1.000000\n",
            "4      2500+     51      51  1.000000       NaN   1.000000  0.980392\n",
            "1  1000–2500     50      42  0.923997  0.705357   0.840000  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weights FIX"
      ],
      "metadata": {
        "id": "n0YZXzFSAFbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import clone\n",
        "\n",
        "# Compute positive rate per bin on TRAIN\n",
        "train_stats = (X_train.assign(y=y_train)\n",
        "               .groupby('amount_bin')['y']\n",
        "               .agg(pos='sum', n='size'))\n",
        "train_stats['pos_rate'] = train_stats['pos']/train_stats['n']\n",
        "\n",
        "# Build positive sample weights inversely to each bin's prevalence, capped\n",
        "median_rate = float(train_stats['pos_rate'].replace(0, np.nan).median())\n",
        "safe_rate   = train_stats['pos_rate'].replace(0, 1e-6)\n",
        "pos_w = (median_rate / safe_rate).clip(1.0, 10.0)  # cap extreme weights\n",
        "bin_pos_weight = pos_w.to_dict()\n",
        "\n",
        "def make_sample_weight(X, y, bin_weights):\n",
        "    w = np.ones(len(y), dtype='float32')\n",
        "    mask = (y == 1)\n",
        "    w[mask] = X.loc[mask, 'amount_bin'].map(bin_weights).fillna(1.0).values\n",
        "    return w\n",
        "\n",
        "w_train = make_sample_weight(X_train, y_train, bin_pos_weight)\n",
        "\n",
        "# Retrain a fresh clone with weights\n",
        "pipe_w = clone(model_current)   # preserves your encoders and RF hyperparams\n",
        "pipe_w.fit(X_train, y_train, rf__sample_weight=w_train)\n",
        "\n",
        "# Re-pick global threshold on VALID (max F1)\n",
        "pv_w = pipe_w.predict_proba(X_valid)[:,1]\n",
        "P_w, R_w, T_w = precision_recall_curve(y_valid, pv_w)\n",
        "F1_w = 2*P_w*R_w/(P_w+R_w+1e-9)\n",
        "thr_star_w = float(T_w[int(np.nanargmax(F1_w[:-1]))])\n",
        "print(\"\\nWeighted model: chosen thr_star_w (VALID, max F1):\", thr_star_w)\n",
        "\n",
        "# BEFORE/AFTER per-bin (global threshold for the weighted model)\n",
        "print(\"\\n=== Weighted model (global thr): per-bin metrics (VALID) ===\")\n",
        "valid_weighted_before = metrics_by_bin(pipe_w, X_valid, y_valid, X_valid['amount_bin'], thr_star_w)\n",
        "print(valid_weighted_before)\n",
        "\n",
        "print(\"\\n=== Weighted model (global thr): per-bin metrics (TEST) ===\")\n",
        "test_weighted_before  = metrics_by_bin(pipe_w, X_test,  y_test,  X_test['amount_bin'],  thr_star_w)\n",
        "print(test_weighted_before)\n",
        "\n",
        "# apply per-bin thresholds to the weighted model\n",
        "thr_map_w = thresholds_per_bin(pipe_w, X_valid, y_valid, X_valid['amount_bin'], strategy=\"max_f1\")\n",
        "pv2_v, pr2_v = predict_with_bin_thresholds(pipe_w, X_valid, X_valid['amount_bin'], thr_map_w, default_thr=thr_star_w)\n",
        "pv2_t, pr2_t = predict_with_bin_thresholds(pipe_w, X_test,  X_test['amount_bin'],  thr_map_w, default_thr=thr_star_w)\n",
        "\n",
        "print(\"\\n=== Weighted model + per-bin thresholds: per-bin metrics (VALID) ===\")\n",
        "print(metrics_by_bin_from_preds(y_valid, pv2_v, pr2_v, X_valid['amount_bin']))\n",
        "\n",
        "print(\"\\n=== Weighted model + per-bin thresholds: per-bin metrics (TEST) ===\")\n",
        "print(metrics_by_bin_from_preds(y_test,  pv2_t, pr2_t, X_test['amount_bin']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5mlhgFO_w0c",
        "outputId": "5dc67a33-17b7-4b81-d861-716dbe2f812c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Weighted model: chosen thr_star_w (VALID, max F1): 0.9787487064232085\n",
            "\n",
            "=== Weighted model (global thr): per-bin metrics (VALID) ===\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32622      48  0.415377  0.995624   0.351351  0.541667\n",
            "2      10–25  25376      32  0.295865  0.995052   0.366667  0.343750\n",
            "0       0–10  16059      17  0.252438  0.994197   0.184211  0.411765\n",
            "8      50–75  10186      51  0.590952  0.992341   0.326923  0.666667\n",
            "9     75–150   3183     115  0.427684  0.946393   0.425926  0.400000\n",
            "3    150–250    953     164  0.702087  0.929356   0.703125  0.548780\n",
            "5    250–500    500     343  0.962020  0.929008   0.911672  0.842566\n",
            "7   500–1000    219     214  0.989381  0.641121   0.978610  0.855140\n",
            "1  1000–2500     49      47  0.977977  0.574468   0.952381  0.851064\n",
            "4      2500+     49      49  1.000000       NaN   1.000000  0.938776\n",
            "\n",
            "=== Weighted model (global thr): per-bin metrics (TEST) ===\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32667      45  0.377331  0.996627   0.347222  0.555556\n",
            "2      10–25  25133      26  0.364108  0.997702   0.324324  0.461538\n",
            "0       0–10  16083      21  0.445957  0.996392   0.458333  0.523810\n",
            "8      50–75  10214      37  0.445533  0.990012   0.208333  0.540541\n",
            "9     75–150   3315     129  0.531906  0.948634   0.537037  0.449612\n",
            "3    150–250    946     163  0.717330  0.929456   0.694444  0.613497\n",
            "5    250–500    503     337  0.958522  0.929400   0.904615  0.872404\n",
            "7   500–1000    235     229  0.987547  0.619360   0.974227  0.825328\n",
            "4      2500+     51      51  1.000000       NaN   1.000000  0.921569\n",
            "1  1000–2500     50      42  0.955262  0.800595   0.925000  0.880952\n",
            "\n",
            "=== Weighted model + per-bin thresholds: per-bin metrics (VALID) ===\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32622      48  0.415377  0.995624   0.415094  0.458333\n",
            "2      10–25  25376      32  0.295865  0.995052   0.370370  0.312500\n",
            "0       0–10  16059      17  0.252438  0.994197   0.555556  0.294118\n",
            "8      50–75  10186      51  0.590952  0.992341   0.625000  0.588235\n",
            "9     75–150   3183     115  0.427684  0.946393   0.418033  0.443478\n",
            "3    150–250    953     164  0.702087  0.929356   0.558594  0.871951\n",
            "5    250–500    500     343  0.962020  0.929008   0.897297  0.967930\n",
            "7   500–1000    219     214  0.989381  0.641121   0.977169  1.000000\n",
            "1  1000–2500     49      47  0.977977  0.574468   0.959184  1.000000\n",
            "4      2500+     49      49  1.000000       NaN   1.000000  1.000000\n",
            "\n",
            "=== Weighted model + per-bin thresholds: per-bin metrics (TEST) ===\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32667      45  0.377331  0.996627   0.440000  0.488889\n",
            "2      10–25  25133      26  0.364108  0.997702   0.333333  0.461538\n",
            "0       0–10  16083      21  0.445957  0.996392   0.571429  0.190476\n",
            "8      50–75  10214      37  0.445533  0.990012   0.533333  0.432432\n",
            "9     75–150   3315     129  0.531906  0.948634   0.476562  0.472868\n",
            "3    150–250    946     163  0.717330  0.929456   0.500000  0.889571\n",
            "5    250–500    503     337  0.958522  0.929400   0.904110  0.979228\n",
            "7   500–1000    235     229  0.987547  0.619360   0.974468  1.000000\n",
            "4      2500+     51      51  1.000000       NaN   1.000000  1.000000\n",
            "1  1000–2500     50      42  0.955262  0.800595   0.840000  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "joblib.dump(pipe_w, \"/content/drive/MyDrive/fraud_model/rf_pipeline_weighted.joblib\")\n",
        "# optional thresholds learned on VALID for the weighted model:\n",
        "with open(\"/content/drive/MyDrive/fraud_model/thresholds_by_amount_bin_weighted.json\",\"w\") as f:\n",
        "    json.dump({str(k): float(v) for k,v in thr_map_w.items()}, f)\n",
        "with open(\"/content/drive/MyDrive/fraud_model/global_threshold_weighted.txt\",\"w\") as f:\n",
        "    f.write(str(float(thr_star_w)))\n",
        "print(\"Saved rf_pipeline_weighted.joblib (+ thresholds if used)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA5O5155AI-G",
        "outputId": "5153d5e5-b9eb-44bc-e6f6-fba6b2ce2672"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved rf_pipeline_weighted.joblib (+ thresholds if used)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cat-Boost"
      ],
      "metadata": {
        "id": "N8XprAumKCXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIjXB5xfPQqG",
        "outputId": "402225ff-58d7-47c6-9618-5c5604a5103f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_curve, average_precision_score, roc_auc_score,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "from catboost import CatBoostClassifier, Pool"
      ],
      "metadata": {
        "id": "WU44qeqcGh8M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/cleaned_fraud_df.csv\")\n",
        "\n",
        "FEATURES = ['age_group','gender_clean','category_clean','amount_bin','merchant','customer']\n",
        "TARGET   = 'fraud'\n",
        "\n",
        "df = df[FEATURES + [TARGET]].copy()\n",
        "y  = df[TARGET].astype(int).values\n",
        "X  = df[FEATURES].copy()"
      ],
      "metadata": {
        "id": "TCY_XKxbJ-z2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.mean())\n",
        "print(\"Valid:\", X_valid.shape, y_valid.mean())\n",
        "print(\"Test :\", X_test.shape,  y_test.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liN-8tvgKBk3",
        "outputId": "81204267-c5c7-4924-b5a8-b8e93e9030d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (416250, 6) 0.012108108108108109\n",
            "Valid: (89196, 6) 0.012108166285483654\n",
            "Test : (89197, 6) 0.012108030539143694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CatBoost Pools with categorical features\n",
        "cat_cols = FEATURES  # pass names directly\n",
        "train_pool = Pool(X_train, y_train, cat_features=cat_cols)\n",
        "valid_pool = Pool(X_valid, y_valid, cat_features=cat_cols)\n",
        "test_pool  = Pool(X_test,  y_test,  cat_features=cat_cols)"
      ],
      "metadata": {
        "id": "sIge8tS_PJJL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model config (imbalance-aware + early stopping on PR-AUC)\n",
        "pos = y_train.sum()\n",
        "neg = len(y_train) - pos\n",
        "scale_pos_weight = (neg / max(pos, 1))  # guard against div-by-zero\n",
        "\n",
        "cb = CatBoostClassifier(\n",
        "    iterations=3000,\n",
        "    learning_rate=0.05,\n",
        "    depth=8,\n",
        "    l2_leaf_reg=6,\n",
        "    loss_function='Logloss',\n",
        "    eval_metric='PRAUC',         # better for imbalance\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_seed=42,\n",
        "    od_type='Iter', od_wait=200, # early stopping patience\n",
        "    verbose=200\n",
        ")\n",
        "\n",
        "cb.fit(train_pool, eval_set=valid_pool, use_best_model=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkYxJVuTPNZM",
        "outputId": "b1552aa3-2b6f-4715-ae42-fe8b6152b00c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.9953018\ttest: 0.9950798\tbest: 0.9950798 (0)\ttotal: 2.01s\tremaining: 1h 40m 29s\n",
            "200:\tlearn: 0.9988701\ttest: 0.9981351\tbest: 0.9981358 (162)\ttotal: 1m 51s\tremaining: 25m 53s\n",
            "400:\tlearn: 0.9992853\ttest: 0.9979964\tbest: 0.9981394 (205)\ttotal: 3m 44s\tremaining: 24m 12s\n",
            "Stopped by overfitting detector  (200 iterations wait)\n",
            "\n",
            "bestTest = 0.9981394474\n",
            "bestIteration = 205\n",
            "\n",
            "Shrink model to first 206 iterations.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7a98f519b650>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global threshold selection (max F1) on VALID\n",
        "def pick_threshold_max_f1(y_true, proba):\n",
        "    P, R, T = precision_recall_curve(y_true, proba)\n",
        "    F1 = 2*P*R/(P+R+1e-9)\n",
        "    # T has length len(P)-1; drop the last F1 which has no threshold\n",
        "    best_idx = int(np.nanargmax(F1[:-1]))\n",
        "    return float(T[best_idx])\n",
        "\n",
        "proba_valid = cb.predict_proba(valid_pool)[:,1]\n",
        "thr_star = pick_threshold_max_f1(y_valid, proba_valid)\n",
        "print(\"Chosen global threshold (VALID, max F1):\", thr_star)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lPZtCkXPg71",
        "outputId": "b8e59c8d-a4bb-40dc-ce72-da5029182a92"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen global threshold (VALID, max F1): 0.9742398392816267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation helpers\n",
        "def evaluate_at_threshold(model, pool, y_true, thr, label=\"\"):\n",
        "    p = model.predict_proba(pool)[:,1]\n",
        "    pred = (p >= float(thr)).astype(int)\n",
        "    ap  = average_precision_score(y_true, p)\n",
        "    auc = roc_auc_score(y_true, p)\n",
        "    print(f\"\\n[{label}] PRAUC={ap:.4f} | ROC-AUC={auc:.4f} | thr={thr:.4f} | prevalence={y_true.mean():.4f}\")\n",
        "    print(classification_report(y_true, pred, digits=3))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_true, pred))\n",
        "    return p, pred\n",
        "\n",
        "def metrics_by_bin_from_preds(y_true, proba, pred, bins_series):\n",
        "    dfm = pd.DataFrame({'bin': bins_series.values, 'y': y_true, 'proba': proba, 'pred': pred})\n",
        "    rows = []\n",
        "    for b, g in dfm.groupby('bin'):\n",
        "        if len(g) == 0:\n",
        "            continue\n",
        "        ap  = average_precision_score(g['y'], g['proba']) if g['y'].sum()>0 else np.nan\n",
        "        auc = roc_auc_score(g['y'], g['proba']) if g['y'].nunique()>1 else np.nan\n",
        "        tp = ((g['pred']==1)&(g['y']==1)).sum()\n",
        "        fp = ((g['pred']==1)&(g['y']==0)).sum()\n",
        "        fn = ((g['pred']==0)&(g['y']==1)).sum()\n",
        "        prec = tp/(tp+fp+1e-9); rec = tp/(tp+fn+1e-9)\n",
        "        rows.append([b, len(g), int(g['y'].sum()), ap, auc, prec, rec])\n",
        "    cols = ['amount_bin','n','frauds','AP','ROC_AUC','Precision','Recall']\n",
        "    return pd.DataFrame(rows, columns=cols).sort_values('n', ascending=False)\n",
        "\n",
        "def thresholds_per_bin_from_valid(y_valid, proba_valid, bin_valid,\n",
        "                                  strategy=\"max_f1\", min_recall=0.5):\n",
        "    \"\"\"\n",
        "    Learn a threshold per amount_bin from the VALID set.\n",
        "    strategy: \"max_f1\" or \"recall_floor\" (uses min_recall).\n",
        "    \"\"\"\n",
        "    dfv = pd.DataFrame({'bin': bin_valid.values, 'y': y_valid, 'p': proba_valid})\n",
        "    thr_map = {}\n",
        "    for b, g in dfv.groupby('bin'):\n",
        "        if g['y'].sum() == 0:\n",
        "            thr_map[b] = 0.999  # no positives in this bin: keep it strict\n",
        "            continue\n",
        "        P, R, T = precision_recall_curve(g['y'], g['p'])\n",
        "        if strategy == \"max_f1\":\n",
        "            F1 = 2*P*R/(P+R+1e-9)\n",
        "            idx = int(np.nanargmax(F1[:-1]))\n",
        "        else:  # \"recall_floor\"\n",
        "            ok = np.where(R[:-1] >= float(min_recall))[0]\n",
        "            idx = ok[-1] if len(ok) else len(T)-1\n",
        "        thr_map[b] = float(T[idx])\n",
        "    return thr_map\n",
        "\n",
        "def predict_with_bin_thresholds(model, X_df, pool, thr_map, default_thr):\n",
        "    p = model.predict_proba(pool)[:,1]\n",
        "    thrs = X_df['amount_bin'].map(thr_map).astype(float).fillna(float(default_thr)).values\n",
        "    pred = (p >= thrs).astype(int)\n",
        "    return p, pred, thrs"
      ],
      "metadata": {
        "id": "EEqODyM-QkmS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Report: Global-threshold performance + per-bin tables\n",
        "p_v, pred_v = evaluate_at_threshold(cb, valid_pool, y_valid, thr_star, label=\"VALID (global thr)\")\n",
        "p_t, pred_t = evaluate_at_threshold(cb, test_pool,  y_test,  thr_star, label=\"TEST  (global thr)\")\n",
        "\n",
        "print(\"\\nPer-bin (VALID) with global threshold:\")\n",
        "print(metrics_by_bin_from_preds(y_valid, p_v, pred_v, X_valid['amount_bin']))\n",
        "\n",
        "print(\"\\nPer-bin (TEST) with global threshold:\")\n",
        "print(metrics_by_bin_from_preds(y_test,  p_t, pred_t, X_test['amount_bin']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0384w2LQtK4",
        "outputId": "0f0aabf0-f4e5-412b-96b2-e0e6e59098b7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[VALID (global thr)] PRAUC=0.9282 | ROC-AUC=0.9982 | thr=0.9742 | prevalence=0.0121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.998     0.999     0.998     88116\n",
            "           1      0.874     0.845     0.859      1080\n",
            "\n",
            "    accuracy                          0.997     89196\n",
            "   macro avg      0.936     0.922     0.929     89196\n",
            "weighted avg      0.997     0.997     0.997     89196\n",
            "\n",
            "Confusion matrix:\n",
            " [[87984   132]\n",
            " [  167   913]]\n",
            "\n",
            "[TEST  (global thr)] PRAUC=0.9298 | ROC-AUC=0.9984 | thr=0.9742 | prevalence=0.0121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.998     0.998     0.998     88117\n",
            "           1      0.851     0.854     0.853      1080\n",
            "\n",
            "    accuracy                          0.996     89197\n",
            "   macro avg      0.925     0.926     0.925     89197\n",
            "weighted avg      0.996     0.996     0.996     89197\n",
            "\n",
            "Confusion matrix:\n",
            " [[87956   161]\n",
            " [  158   922]]\n",
            "\n",
            "Per-bin (VALID) with global threshold:\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32622      48  0.594167  0.997179   0.684211  0.541667\n",
            "2      10–25  25376      32  0.449766  0.995857   0.636364  0.218750\n",
            "0       0–10  16059      17  0.557836  0.996181   0.777778  0.411765\n",
            "8      50–75  10186      51  0.647501  0.991543   0.642857  0.529412\n",
            "9     75–150   3183     115  0.601069  0.960681   0.651163  0.486957\n",
            "3    150–250    953     164  0.908099  0.977975   0.826347  0.841463\n",
            "5    250–500    500     343  0.987679  0.977103   0.909574  0.997085\n",
            "7   500–1000    219     214  0.996619  0.890654   0.981651  1.000000\n",
            "1  1000–2500     49      47  0.990781  0.797872   0.959184  1.000000\n",
            "4      2500+     49      49  1.000000       NaN   1.000000  1.000000\n",
            "\n",
            "Per-bin (TEST) with global threshold:\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32667      45  0.575428  0.997911   0.617647  0.466667\n",
            "2      10–25  25133      26  0.541272  0.996925   0.555556  0.384615\n",
            "0       0–10  16083      21  0.609922  0.997376   0.692308  0.428571\n",
            "8      50–75  10214      37  0.509552  0.992341   0.571429  0.540541\n",
            "9     75–150   3315     129  0.697962  0.964001   0.717172  0.550388\n",
            "3    150–250    946     163  0.875569  0.967919   0.761364  0.822086\n",
            "5    250–500    503     337  0.984435  0.974062   0.896000  0.997033\n",
            "7   500–1000    235     229  0.999755  0.990902   0.978632  1.000000\n",
            "4      2500+     51      51  1.000000       NaN   1.000000  1.000000\n",
            "1  1000–2500     50      42  0.985400  0.922619   0.854167  0.976190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Per-bin thresholds (Fix #1) learned on VALID\n",
        "# You can switch to strategy=\"recall_floor\", e.g., min_recall=0.5 for small bins.\n",
        "thr_map = thresholds_per_bin_from_valid(\n",
        "    y_valid, p_v, X_valid['amount_bin'], strategy=\"max_f1\", min_recall=0.5\n",
        ")\n",
        "\n",
        "p_vb, pred_vb, thrs_vb = predict_with_bin_thresholds(cb, X_valid, valid_pool, thr_map, default_thr=thr_star)\n",
        "p_tb, pred_tb, thrs_tb = predict_with_bin_thresholds(cb, X_test,  test_pool,  thr_map, default_thr=thr_star)\n",
        "\n",
        "print(\"\\nPer-bin (VALID) with per-bin thresholds:\")\n",
        "print(metrics_by_bin_from_preds(y_valid, p_vb, pred_vb, X_valid['amount_bin']))\n",
        "\n",
        "print(\"\\nPer-bin (TEST) with per-bin thresholds:\")\n",
        "print(metrics_by_bin_from_preds(y_test,  p_tb, pred_tb, X_test['amount_bin']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqSmp7nKQxo4",
        "outputId": "6fd89412-9382-4b4e-8e77-f00a23bdd6af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Per-bin (VALID) with per-bin thresholds:\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32622      48  0.594167  0.997179   0.684211  0.541667\n",
            "2      10–25  25376      32  0.449766  0.995857   0.583333  0.437500\n",
            "0       0–10  16059      17  0.557836  0.996181   0.625000  0.588235\n",
            "8      50–75  10186      51  0.647501  0.991543   0.607843  0.607843\n",
            "9     75–150   3183     115  0.601069  0.960681   0.533784  0.686957\n",
            "3    150–250    953     164  0.908099  0.977975   0.835366  0.835366\n",
            "5    250–500    500     343  0.987679  0.977103   0.928767  0.988338\n",
            "7   500–1000    219     214  0.996619  0.890654   0.981651  1.000000\n",
            "1  1000–2500     49      47  0.990781  0.797872   0.959184  1.000000\n",
            "4      2500+     49      49  1.000000       NaN   1.000000  1.000000\n",
            "\n",
            "Per-bin (TEST) with per-bin thresholds:\n",
            "  amount_bin      n  frauds        AP   ROC_AUC  Precision    Recall\n",
            "6      25–50  32667      45  0.575428  0.997911   0.617647  0.466667\n",
            "2      10–25  25133      26  0.541272  0.996925   0.432432  0.615385\n",
            "0       0–10  16083      21  0.609922  0.997376   0.576923  0.714286\n",
            "8      50–75  10214      37  0.509552  0.992341   0.552632  0.567568\n",
            "9     75–150   3315     129  0.697962  0.964001   0.546012  0.689922\n",
            "3    150–250    946     163  0.875569  0.967919   0.766082  0.803681\n",
            "5    250–500    503     337  0.984435  0.974062   0.912568  0.991098\n",
            "7   500–1000    235     229  0.999755  0.990902   0.978632  1.000000\n",
            "4      2500+     51      51  1.000000       NaN   1.000000  0.980392\n",
            "1  1000–2500     50      42  0.985400  0.922619   0.891304  0.976190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save artifacts\n",
        "save_dir = Path(\"/content/drive/MyDrive/fraud_model\")\n",
        "model_path= save_dir / \"catboost_fraud_model.cbm\"\n",
        "thresholds_path_cat= save_dir / \"thresholds_by_amount_bin_cat.json\"\n",
        "golobal_threshold_path_cat= save_dir / \"global_threshold_cat.txt\"\n",
        "\n",
        "cb.save_model(model_path)  # CatBoost native format\n",
        "with open(thresholds_path_cat, \"w\") as f:\n",
        "    json.dump({str(k): float(v) for k, v in thr_map.items()}, f)\n",
        "with open(golobal_threshold_path_cat, \"w\") as f:\n",
        "    f.write(str(float(thr_star)))\n",
        "\n",
        "print(f\"\\nSaved:\\n- {model_path}\\n- {thresholds_path_cat}\\n- {golobal_threshold_path_cat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYmxXj36VsCy",
        "outputId": "4ac7152f-ef9c-491a-cff2-5cec38273f50"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved:\n",
            "- /content/drive/MyDrive/fraud_model/catboost_fraud_model.cbm\n",
            "- /content/drive/MyDrive/fraud_model/thresholds_by_amount_bin_cat.json\n",
            "- /content/drive/MyDrive/fraud_model/global_threshold_cat.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feature importance\n",
        "imp = cb.get_feature_importance(type='PredictionValuesChange', data=train_pool)\n",
        "fi = pd.Series(imp, index=FEATURES).sort_values(ascending=False)\n",
        "print(\"\\nFeature importance (PredictionValuesChange):\")\n",
        "print(fi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vByyEPK2Wea-",
        "outputId": "1a744364-0cb2-4ae1-e863-29761497e068"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature importance (PredictionValuesChange):\n",
            "merchant          37.207447\n",
            "category_clean    19.461013\n",
            "amount_bin        19.263217\n",
            "customer          13.410962\n",
            "age_group          5.520114\n",
            "gender_clean       5.137248\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMTmMuyBY4aX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}