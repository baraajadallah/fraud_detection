{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j_e4lBOJQdZH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "-SaetPgIe6-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TargetEncoder\n",
        "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Smoothed target encoding: enc(v) = (sum_y + prior * m) / (count + m)\n",
        "    Unseen -> prior.\n",
        "    \"\"\"\n",
        "    def __init__(self, cols, smoothing=200):\n",
        "        self.cols = cols\n",
        "        self.smoothing = smoothing\n",
        "        self.maps_ = {}\n",
        "        self.prior_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = X.copy(); y = pd.Series(y)\n",
        "        self.prior_ = float(y.mean())\n",
        "        self.maps_ = {}\n",
        "        for c in self.cols:\n",
        "            s = X[c].astype(str)\n",
        "            stats = y.groupby(s).agg(['sum','count'])\n",
        "            enc = (stats['sum'] + self.prior_ * self.smoothing) / (stats['count'] + self.smoothing)\n",
        "            self.maps_[c] = enc\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        feats = []\n",
        "        for c in self.cols:\n",
        "            m = self.maps_.get(c, pd.Series(dtype=float))\n",
        "            v = X[c].astype(str).map(m).fillna(self.prior_)\n",
        "            feats.append(v.astype('float32').to_numpy().reshape(-1, 1))\n",
        "        return np.hstack(feats)\n",
        "\n",
        "# CountEncoder\n",
        "class CountEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Unsupervised frequency (count) encoding with optional log scaling.\n",
        "    \"\"\"\n",
        "    def __init__(self, cols, normalize=False, log1p=True):\n",
        "        self.cols = cols\n",
        "        self.normalize = normalize\n",
        "        self.log1p = log1p\n",
        "        self.maps_ = {}\n",
        "        self.n_train_ = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = X.copy()\n",
        "        self.n_train_ = len(X)\n",
        "        self.maps_ = {}\n",
        "        for c in self.cols:\n",
        "            vc = X[c].astype(str).value_counts()\n",
        "            if self.normalize:\n",
        "                vc = vc / self.n_train_\n",
        "            self.maps_[c] = vc\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        feats = []\n",
        "        for c in self.cols:\n",
        "            m = self.maps_.get(c, pd.Series(dtype=float))\n",
        "            enc = X[c].astype(str).map(m).fillna(0.0)\n",
        "            if self.log1p and not self.normalize:\n",
        "                enc = np.log1p(enc)  # log(count)\n",
        "            elif self.log1p and self.normalize:\n",
        "                enc = np.log1p(enc * self.n_train_)  # ~log(count)\n",
        "            feats.append(enc.astype('float32').to_numpy().reshape(-1, 1))\n",
        "        return np.hstack(feats)"
      ],
      "metadata": {
        "id": "60cpAHaGQtdn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features expected by the saved pipeline\n",
        "FEATURES = ['age_group','gender_clean','category_clean','amount_bin','merchant','customer']\n",
        "\n",
        "# Amount binning identical to training\n",
        "AMOUNT_EDGES = [0, 10, 25, 50, 75, 150, 250, 500, 1000, 2500, np.inf]\n",
        "AMOUNT_LABELS = ['0–10','10–25','25–50','50–75','75–150','150–250','250–500','500–1000','1000–2500','2500+']\n",
        "\n",
        "def make_amount_bin(amount_series: pd.Series) -> pd.Series:\n",
        "    # ensure numeric\n",
        "    s = pd.to_numeric(amount_series, errors='coerce').fillna(-1)\n",
        "    bins = pd.cut(\n",
        "        s,\n",
        "        bins=AMOUNT_EDGES,\n",
        "        labels=AMOUNT_LABELS,\n",
        "        right=False,          # [a, b)\n",
        "        include_lowest=True\n",
        "    ).astype(str)\n",
        "    # values <0 (missing/invalid) will become 'nan' string; keep as 'nan' so encoders handle as unseen\n",
        "    return bins\n",
        "\n",
        "# Optional: light normalization for strings\n",
        "def _norm_str(x):\n",
        "    if pd.isna(x): return x\n",
        "    return str(x).strip().replace('\\u2014','–').replace('\\u2013','–')  # unify dash to en dash\n",
        "\n",
        "# Paths (edit to your artifact names)\n",
        "MODEL_PATH      = Path(\"/content/drive/MyDrive/fraud_model/rf_pipeline_weighted.joblib\")\n",
        "THRESHOLDS_PATH = Path(\"/content/drive/MyDrive/fraud_model/thresholds_by_amount_bin_weighted.json\")\n",
        "GLOBAL_THR_PATH = Path(\"/content/drive/MyDrive/fraud_model/global_threshold_weighted.txt\")"
      ],
      "metadata": {
        "id": "aVuXeCQFQusZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained pipeline (includes OneHot + TE + Count encoders)\n",
        "model = joblib.load(MODEL_PATH)\n",
        "\n",
        "# Load thresholds if available (per-bin + default). If not present, fall back to 0.5.\n",
        "thr_map = None\n",
        "default_thr = 0.5\n",
        "if THRESHOLDS_PATH.exists():\n",
        "    thr_map = json.load(open(THRESHOLDS_PATH))\n",
        "    # ensure float\n",
        "    thr_map = {str(k): float(v) for k,v in thr_map.items()}\n",
        "if GLOBAL_THR_PATH.exists():\n",
        "    default_thr = float(open(GLOBAL_THR_PATH).read().strip())\n",
        "print(\"Loaded model:\", MODEL_PATH)\n",
        "print(\"Per-bin thresholds:\", \"yes\" if thr_map is not None else \"no\", \"| default thr:\", default_thr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAL3v9ctQztq",
        "outputId": "125185dd-843d-496e-9d5b-a8015d6ca5f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model: /content/drive/MyDrive/fraud_model/rf_pipeline_weighted.joblib\n",
            "Per-bin thresholds: yes | default thr: 0.9787487064232085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_inference_frame(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df_raw.copy()\n",
        "\n",
        "    # If amount_bin missing, construct it from 'amount'\n",
        "    if 'amount_bin' not in df.columns:\n",
        "        if 'amount' not in df.columns:\n",
        "            raise ValueError(\"Incoming data must have either 'amount_bin' or 'amount'.\")\n",
        "        df['amount_bin'] = make_amount_bin(df['amount'])\n",
        "\n",
        "    # Light normalization for categorical inputs\n",
        "    for c in ['age_group','gender_clean','category_clean','amount_bin','merchant','customer']:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].map(_norm_str)\n",
        "        else:\n",
        "            # Create missing columns as 'nan' strings; encoders will treat as unseen\n",
        "            df[c] = 'nan'\n",
        "\n",
        "    # Canonicalize age & gender where possible\n",
        "    if 'age_group' in df.columns:\n",
        "        df['age_group'] = df['age_group'].astype(str).str.upper()\n",
        "        df.loc[~df['age_group'].isin(['0','1','2','3','4','5','6','U']), 'age_group'] = 'U'\n",
        "\n",
        "    if 'gender_clean' in df.columns:\n",
        "        df['gender_clean'] = df['gender_clean'].astype(str).str.upper()\n",
        "        df.loc[~df['gender_clean'].isin(['F','M','E','U']), 'gender_clean'] = 'U'\n",
        "\n",
        "    # Ensure required columns exist and order them\n",
        "    missing = [c for c in FEATURES if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns for the model: {missing}\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "k_t3lMcgQ6yH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_proba_only(df_new: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"Return fraud probability for each row.\"\"\"\n",
        "    df_prep = prepare_inference_frame(df_new)\n",
        "    proba = model.predict_proba(df_prep[FEATURES])[:, 1]\n",
        "    return proba\n",
        "\n",
        "def predict_labels(df_new: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Returns a DataFrame with proba, threshold used, and label.\n",
        "    Uses per-bin thresholds if available, else global default.\n",
        "    \"\"\"\n",
        "    df_prep = prepare_inference_frame(df_new)\n",
        "    proba = model.predict_proba(df_prep[FEATURES])[:, 1]\n",
        "    if thr_map is not None:\n",
        "        thrs = df_prep['amount_bin'].map(thr_map).astype(float).fillna(float(default_thr)).values\n",
        "    else:\n",
        "        thrs = np.full(len(df_prep), float(default_thr), dtype=float)\n",
        "    pred = (proba >= thrs).astype(int)\n",
        "\n",
        "    out = df_prep.copy()\n",
        "    out['proba_fraud'] = proba\n",
        "    out['threshold_used'] = thrs\n",
        "    out['pred_fraud'] = pred\n",
        "    return out"
      ],
      "metadata": {
        "id": "P-KjFYlLQ9pz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example new data CSV; must include either 'amount' or a prebuilt 'amount_bin'\n",
        "new_df = pd.read_csv(\"new_transactions.csv\")\n",
        "\n",
        "scored = predict_labels(new_df)\n",
        "\n",
        "# Keep only a tidy output\n",
        "cols_to_show = (['customer','merchant','amount','amount_bin','age_group','gender_clean','category_clean']\n",
        "                if 'amount' in scored.columns else\n",
        "                ['customer','merchant','amount_bin','age_group','gender_clean','category_clean'])\n",
        "cols_to_show = [c for c in cols_to_show if c in scored.columns]\n",
        "result = scored[cols_to_show + ['proba_fraud','threshold_used','pred_fraud']]\n",
        "\n",
        "print(result.head(10))\n",
        "result.to_csv(\"new_transactions_scored.csv\", index=False)\n",
        "print(\"Saved: new_transactions_scored.csv\")\n"
      ],
      "metadata": {
        "id": "z5lbdNVRT4NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cat-Boost"
      ],
      "metadata": {
        "id": "cpja23Rge-zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyW3KXTHfHza",
        "outputId": "7403b383-3c56-405c-843d-9a21db7fc1ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n",
        "from catboost import CatBoostClassifier, Pool"
      ],
      "metadata": {
        "id": "KYBnX__4fApR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features expected by the model\n",
        "features = ['age_group','gender_clean','category_clean','amount_bin','merchant','customer']\n",
        "\n",
        "# Amount binning\n",
        "amount_edges  = [0, 10, 25, 50, 75, 150, 250, 500, 1000, 2500, np.inf]\n",
        "amount_labels = ['0–10','10–25','25–50','50–75','75–150','150–250','250–500','500–1000','1000–2500','2500+']\n",
        "\n",
        "# Model loading\n",
        "model_path= Path(\"/content/drive/MyDrive/fraud_model/catboost_fraud_model.cbm\")\n",
        "thresholds_path= Path(\"/content/drive/MyDrive/fraud_model/thresholds_by_amount_bin_cat.json\")\n",
        "global_threshold= Path(\"/content/drive/MyDrive/fraud_model/global_threshold_cat.txt\")\n"
      ],
      "metadata": {
        "id": "EC3etEeBfI8F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper functions\n",
        "def _norm_dash(s: str) -> str:\n",
        "    \"\"\"Normalize hyphens to en dash to keep amount_bin labels consistent.\"\"\"\n",
        "    if pd.isna(s): return s\n",
        "    return str(s).replace('-', '–').replace('\\u2013','–').replace('\\u2014','–').strip()\n",
        "\n",
        "def make_amount_bin(amount_series: pd.Series) -> pd.Series:\n",
        "    \"\"\"Create amount_bin from raw amount using training-time edges & labels.\"\"\"\n",
        "    a = pd.to_numeric(amount_series, errors='coerce')\n",
        "    bins = pd.cut(a, bins=amount_edges, labels=amount_labels, right=False, include_lowest=True)\n",
        "    return bins.astype(str)\n",
        "\n",
        "def prepare_inference_frame(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Ensure the input frame has all expected columns, clean strings, and build amount_bin if missing.\"\"\"\n",
        "    df = df_raw.copy()\n",
        "\n",
        "    # Build amount_bin if you only receive raw 'amount'\n",
        "    if 'amount_bin' not in df.columns:\n",
        "        if 'amount' not in df.columns:\n",
        "            raise ValueError(\"Incoming data must include either 'amount_bin' or 'amount'.\")\n",
        "        df['amount_bin'] = make_amount_bin(df['amount'])\n",
        "\n",
        "    # Normalize & coerce categorical strings\n",
        "    for c in ['age_group','gender_clean','category_clean','amount_bin','merchant','customer']:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(str).map(_norm_dash)\n",
        "        else:\n",
        "            df[c] = 'nan'  # model handles unseen values\n",
        "\n",
        "    # Canonicalize small vocab fields\n",
        "    df['age_group'] = df['age_group'].str.upper()\n",
        "    df.loc[~df['age_group'].isin(['0','1','2','3','4','5','6','U']), 'age_group'] = 'U'\n",
        "\n",
        "    df['gender_clean'] = df['gender_clean'].str.upper()\n",
        "    df.loc[~df['gender_clean'].isin(['F','M','E','U']), 'gender_clean'] = 'U'\n",
        "\n",
        "    # Ensure column order & presence\n",
        "    missing = [c for c in features if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns: {missing}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_artifacts(model_path=model_path, thr_map_path=thresholds_path, global_thr_path=global_threshold):\n",
        "    \"\"\"Load CatBoost model and (optionally) the per-bin threshold map + global default.\"\"\"\n",
        "    model = CatBoostClassifier()\n",
        "    model.load_model(str(model_path))\n",
        "\n",
        "    thr_map = None\n",
        "    if thr_map_path.exists():\n",
        "        raw = json.load(open(thr_map_path, 'r'))\n",
        "        # normalize keys (dashes etc.) to be safe\n",
        "        thr_map = { _norm_dash(k): float(v) for k, v in raw.items() }\n",
        "\n",
        "    default_thr = 0.5\n",
        "    if global_thr_path.exists():\n",
        "        default_thr = float(open(global_thr_path, 'r').read().strip())\n",
        "\n",
        "    return model, thr_map, default_thr"
      ],
      "metadata": {
        "id": "3NIXUCW5ft8d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scoring functions\n",
        "def predict_proba_only(df_new: pd.DataFrame,\n",
        "                       model: CatBoostClassifier,\n",
        "                       cat_features=features) -> np.ndarray:\n",
        "    \"\"\"Return fraud probability for each row.\"\"\"\n",
        "    df_prep = prepare_inference_frame(df_new)\n",
        "    pool = Pool(df_prep[features], cat_features=cat_features)\n",
        "    proba = model.predict_proba(pool)[:, 1]\n",
        "    return proba\n",
        "\n",
        "def predict_with_thresholds(df_new: pd.DataFrame,\n",
        "                            model: CatBoostClassifier,\n",
        "                            thr_map: dict | None = None,\n",
        "                            default_thr: float = 0.5,\n",
        "                            cat_features=features) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Score records and apply per-bin thresholds if provided.\n",
        "    Returns a DataFrame with proba_fraud, threshold_used, pred_fraud.\n",
        "    \"\"\"\n",
        "    df_prep = prepare_inference_frame(df_new)\n",
        "    pool = Pool(df_prep[features], cat_features=cat_features)\n",
        "    proba = model.predict_proba(pool)[:, 1]\n",
        "\n",
        "    if thr_map:\n",
        "        thrs = df_prep['amount_bin'].map(thr_map).astype(float).fillna(float(default_thr)).values\n",
        "    else:\n",
        "        thrs = np.full(len(df_prep), float(default_thr), dtype=float)\n",
        "\n",
        "    pred = (proba >= thrs).astype(int)\n",
        "\n",
        "    out = df_prep.copy()\n",
        "    out['proba_fraud']   = proba\n",
        "    out['threshold_used'] = thrs\n",
        "    out['pred_fraud']     = pred\n",
        "    return out"
      ],
      "metadata": {
        "id": "k32rPhgXfyH4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example usage\n",
        "# Load model + thresholds\n",
        "model, thr_map, default_thr = load_artifacts()\n",
        "\n",
        "new_df = pd.read_csv(\"/content/drive/MyDrive/cleaned_fraud_df.csv\").sample(20)\n",
        "\n",
        "scored = predict_with_thresholds(new_df, model, thr_map, default_thr)\n",
        "# view results\n",
        "cols_to_show = [c for c in ['customer','merchant','amount','amount_bin','age_group','gender_clean','category_clean'] if c in scored.columns]\n",
        "result = scored[cols_to_show + ['proba_fraud','threshold_used','pred_fraud']]"
      ],
      "metadata": {
        "id": "Yc_1cmrigOa7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "abVT049eg_iX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}